apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-config
  namespace: investment-platform
  labels:
    app: kafka
data:
  server.properties: |
    # Basic Kafka Configuration
    broker.id=1
    listeners=PLAINTEXT://0.0.0.0:9092
    advertised.listeners=PLAINTEXT://kafka:9092
    
    # Zookeeper Configuration
    zookeeper.connect=zookeeper:2181
    zookeeper.connection.timeout.ms=18000
    
    # Log Configuration
    log.dirs=/kafka/logs
    num.network.threads=3
    num.io.threads=8
    socket.send.buffer.bytes=102400
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600
    
    # Partition Configuration
    num.partitions=3
    num.recovery.threads.per.data.dir=1
    offsets.topic.replication.factor=1
    transaction.state.log.replication.factor=1
    transaction.state.log.min.isr=1
    
    # Log Retention Configuration
    log.retention.hours=168
    log.retention.bytes=1073741824
    log.segment.bytes=1073741824
    log.retention.check.interval.ms=300000
    
    # Cleanup Configuration
    log.cleanup.policy=delete
    delete.topic.enable=true
    
    # Group Configuration
    group.initial.rebalance.delay.ms=0
    
    # Compression
    compression.type=producer
    
    # Security (for future enhancement)
    security.inter.broker.protocol=PLAINTEXT
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: zookeeper
  namespace: investment-platform
  labels:
    app: zookeeper
    tier: messaging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
        tier: messaging
    spec:
      containers:
      - name: zookeeper
        image: confluentinc/cp-zookeeper:7.4.1
        ports:
        - containerPort: 2181
        env:
        - name: ZOOKEEPER_CLIENT_PORT
          value: "2181"
        - name: ZOOKEEPER_TICK_TIME
          value: "2000"
        - name: ZOOKEEPER_SYNC_LIMIT
          value: "2"
        - name: ZOOKEEPER_INIT_LIMIT
          value: "5"
        - name: ZOOKEEPER_MAX_CLIENT_CNXNS
          value: "60"
        - name: ZOOKEEPER_AUTOPURGE_SNAP_RETAIN_COUNT
          value: "3"
        - name: ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL
          value: "24"
        volumeMounts:
        - name: zookeeper-data
          mountPath: /var/lib/zookeeper/data
        - name: zookeeper-logs
          mountPath: /var/lib/zookeeper/log
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - "echo ruok | nc localhost 2181 | grep imok"
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - "echo ruok | nc localhost 2181 | grep imok"
          initialDelaySeconds: 10
          periodSeconds: 10
      volumes:
      - name: zookeeper-data
        persistentVolumeClaim:
          claimName: zookeeper-data-pvc
      - name: zookeeper-logs
        persistentVolumeClaim:
          claimName: zookeeper-logs-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper
  namespace: investment-platform
  labels:
    app: zookeeper
    tier: messaging
spec:
  type: ClusterIP
  ports:
  - port: 2181
    targetPort: 2181
    protocol: TCP
  selector:
    app: zookeeper
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka
  namespace: investment-platform
  labels:
    app: kafka
    tier: messaging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
        tier: messaging
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9308"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.4.1
        ports:
        - containerPort: 9092
          name: kafka
        - containerPort: 9308
          name: metrics
        env:
        - name: KAFKA_BROKER_ID
          value: "1"
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper:2181"
        - name: KAFKA_ADVERTISED_LISTENERS
          value: "PLAINTEXT://kafka:9092"
        - name: KAFKA_LISTENERS
          value: "PLAINTEXT://0.0.0.0:9092"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
          value: "1"
        - name: KAFKA_NUM_PARTITIONS
          value: "3"
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: "true"
        - name: KAFKA_DELETE_TOPIC_ENABLE
          value: "true"
        - name: KAFKA_LOG_RETENTION_HOURS
          value: "168"
        - name: KAFKA_LOG_RETENTION_BYTES
          value: "1073741824"
        - name: KAFKA_LOG_SEGMENT_BYTES
          value: "1073741824"
        - name: KAFKA_HEAP_OPTS
          value: "-Xmx512M -Xms256M"
        - name: KAFKA_JMX_PORT
          value: "9999"
        - name: KAFKA_JMX_HOSTNAME
          value: "localhost"
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka/data
        - name: kafka-config
          mountPath: /etc/kafka/server.properties
          subPath: server.properties
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - "kafka-broker-api-versions --bootstrap-server localhost:9092"
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - "kafka-broker-api-versions --bootstrap-server localhost:9092"
          initialDelaySeconds: 30
          periodSeconds: 10
      - name: kafka-exporter
        image: danielqsj/kafka-exporter:latest
        ports:
        - containerPort: 9308
          name: metrics
        args:
        - --kafka.server=localhost:9092
        - --web.listen-address=0.0.0.0:9308
        - --log.level=info
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
      volumes:
      - name: kafka-data
        persistentVolumeClaim:
          claimName: kafka-data-pvc
      - name: kafka-config
        configMap:
          name: kafka-config
---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: investment-platform
  labels:
    app: kafka
    tier: messaging
spec:
  type: ClusterIP
  ports:
  - port: 9092
    targetPort: 9092
    protocol: TCP
    name: kafka
  - port: 9308
    targetPort: 9308
    protocol: TCP
    name: metrics
  selector:
    app: kafka
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: zookeeper-data-pvc
  namespace: investment-platform
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: zookeeper-logs-pvc
  namespace: investment-platform
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kafka-data-pvc
  namespace: investment-platform
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
---
apiVersion: batch/v1
kind: Job
metadata:
  name: kafka-topics-init
  namespace: investment-platform
  labels:
    app: kafka-init
spec:
  template:
    metadata:
      labels:
        app: kafka-init
    spec:
      restartPolicy: Never
      containers:
      - name: kafka-init
        image: confluentinc/cp-kafka:7.4.1
        command:
        - sh
        - -c
        - |
          echo "Waiting for Kafka to be ready..."
          until kafka-broker-api-versions --bootstrap-server kafka:9092; do
            sleep 5
          done
          
          echo "Creating Kafka topics..."
          
          # Authentication events
          kafka-topics --bootstrap-server kafka:9092 --create --topic auth.user.events --partitions 3 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic auth.session.events --partitions 3 --replication-factor 1 --if-not-exists
          
          # Portfolio events
          kafka-topics --bootstrap-server kafka:9092 --create --topic portfolio.created --partitions 3 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic portfolio.updated --partitions 3 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic portfolio.deleted --partitions 3 --replication-factor 1 --if-not-exists
          
          # Trade events
          kafka-topics --bootstrap-server kafka:9092 --create --topic trade.executed --partitions 5 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic trade.settled --partitions 3 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic trade.failed --partitions 3 --replication-factor 1 --if-not-exists
          
          # Market data events
          kafka-topics --bootstrap-server kafka:9092 --create --topic market.prices --partitions 10 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic market.corporate-actions --partitions 3 --replication-factor 1 --if-not-exists
          
          # Audit and compliance events
          kafka-topics --bootstrap-server kafka:9092 --create --topic audit.logs --partitions 5 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic compliance.violations --partitions 3 --replication-factor 1 --if-not-exists
          
          # Notification events
          kafka-topics --bootstrap-server kafka:9092 --create --topic notifications.email --partitions 3 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic notifications.sms --partitions 3 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic notifications.push --partitions 3 --replication-factor 1 --if-not-exists
          
          # Reporting events
          kafka-topics --bootstrap-server kafka:9092 --create --topic report.generation.requested --partitions 3 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic report.generation.completed --partitions 3 --replication-factor 1 --if-not-exists
          
          # Dead letter queues
          kafka-topics --bootstrap-server kafka:9092 --create --topic dlq.auth --partitions 1 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic dlq.portfolio --partitions 1 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic dlq.trade --partitions 1 --replication-factor 1 --if-not-exists
          kafka-topics --bootstrap-server kafka:9092 --create --topic dlq.notification --partitions 1 --replication-factor 1 --if-not-exists
          
          echo "Kafka topics created successfully!"
          
          # List all topics
          echo "Current topics:"
          kafka-topics --bootstrap-server kafka:9092 --list
      
      backoffLimit: 5
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-ui
  namespace: investment-platform
  labels:
    app: kafka-ui
    tier: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-ui
  template:
    metadata:
      labels:
        app: kafka-ui
        tier: monitoring
    spec:
      containers:
      - name: kafka-ui
        image: provectuslabs/kafka-ui:latest
        ports:
        - containerPort: 8080
        env:
        - name: KAFKA_CLUSTERS_0_NAME
          value: "investment-platform-cluster"
        - name: KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS
          value: "kafka:9092"
        - name: KAFKA_CLUSTERS_0_ZOOKEEPER
          value: "zookeeper:2181"
        - name: KAFKA_CLUSTERS_0_READONLY
          value: "false"
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "200m"
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-ui
  namespace: investment-platform
  labels:
    app: kafka-ui
    tier: monitoring
spec:
  type: ClusterIP
  ports:
  - port: 8080
    targetPort: 8080
    protocol: TCP
  selector:
    app: kafka-ui